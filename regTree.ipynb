{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mode, median\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1567822567.8869746\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "class DecisionTree:\n",
    "    tree = {}\n",
    "    train_df = pd.DataFrame()\n",
    "    label_of_train_data = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    \n",
    "    def find_for_numerical_data(self, row, col_name, val):\n",
    "        if row[col_name] <= float(val):\n",
    "            return 0 #left branch\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\n",
    "    def find_for_categorical_data(self, row, col_name, val):\n",
    "        if row[col_name] == val:\n",
    "            return 0    \n",
    "        else:\n",
    "            return 1 \n",
    "\n",
    "\n",
    "    def map_col_to_index(self, df):\n",
    "        global col_to_idx        \n",
    "        i = 0\n",
    "        for col_nm in df.columns:\n",
    "            col_to_idx[i] = col_nm\n",
    "            i = i + 1\n",
    "\n",
    "\n",
    "    def is_numerical(self, feature_nm):\n",
    "        numerical_features =['YrSold','MoSold','MiscVal','PoolArea','ScreenPorch','3SsnPorch','EnclosedPorch','OpenPorchSF',\n",
    "                             'WoodDeckSF','GarageArea','GarageCars','GarageYrBlt','Fireplaces','TotRmsAbvGrd','Kitchen','Bedroom',\n",
    "                             'LotFrontage','LotArea','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                             'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath',\n",
    "                             'HalfBath']\n",
    "        \n",
    "        return feature_nm in numerical_features\n",
    "\n",
    "\n",
    "    def util_mse(self, x):   \n",
    "        if(x.shape[0] == 0):\n",
    "            return 0;     \n",
    "        mean_x = x.mean()\n",
    "        return np.square([x1 - mean_x for x1 in x]).sum()\n",
    "\n",
    "\n",
    "    def find_mean_squared_error(self, x, y): #x and y are numpy 2d arrays\n",
    "        x = x[:, -1]\n",
    "        y = y[:, -1]\n",
    "\n",
    "        mean_of_left_data = self.util_mse(x)\n",
    "        mean_of_right_data = self.util_mse(y)\n",
    "\n",
    "        total_len = len(x) + len(y)\n",
    "        weighted_mean = (len(x) / total_len * mean_of_left_data) + (len(y) / total_len * mean_of_right_data)\n",
    "\n",
    "        # print(\"weighted_mean: \",weighted_mean)\n",
    "        return weighted_mean\n",
    "\n",
    "\n",
    "    def drop_columns(self, df):\n",
    "        # print(df.info())\n",
    "        # observed the columns which had NAN in >1/2 the no. of rows of train file and dropped them\n",
    "        df.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], axis=1, inplace=True)\n",
    "        # print(df.info())\n",
    "        return df\n",
    "\n",
    "\n",
    "    def clean_data(self, df):\n",
    "        df = self.drop_columns(df)\n",
    "        for col_name in df.columns:\n",
    "            if(self.is_numerical(col_name)):\n",
    "                df[col_name].fillna(df[col_name].mean(), inplace=True)\n",
    "            else:\n",
    "                df[col_name].fillna(df[col_name].mode()[0], inplace=True)\n",
    "                # mode()[0]: reqd when there are mulitple modes (val occuring equal no. of times..)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def train_validation_split(self, df):\n",
    "        dataLen=int(1*df.shape[0])\n",
    "        return df.iloc[0:dataLen], df.iloc[dataLen:,0:]\n",
    "\n",
    "\n",
    "    def is_pure(self, data):#data: a numpy 2D array\n",
    "        sales_data_label=data[:,-1]\n",
    "        set_label=set(sales_data_label);\n",
    "        if(len(set_label)>1):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    def find_potential_splits(self, data):\n",
    "        global col_to_idx\n",
    "        potential_split_dict = {}\n",
    "        for col_idx in range(0, data.shape[1]-1):#data.shape[1]-1, coz the last col is the final SalesPrice col(label)\n",
    "            unique_col=np.unique(data[:, col_idx])\n",
    "            potential_split_dict[col_idx]=[]\n",
    "            if self.is_numerical(col_to_idx[col_idx]):\n",
    "                for row_idx in range(1, unique_col.shape[0]):\n",
    "                    prev = unique_col[row_idx-1]\n",
    "                    nxt = unique_col[row_idx]\n",
    "                    potential_split_dict[col_idx].append((prev+nxt)/2)\n",
    "            else:\n",
    "                potential_split_dict[col_idx].extend(unique_col) #don't use append; use extend\n",
    "\n",
    "        return potential_split_dict\n",
    "\n",
    "\n",
    "    def split_data(self, split_col_idx, split_val, data):\n",
    "        global col_to_idx\n",
    "        col_name=col_to_idx[split_col_idx]\n",
    "        col=data[:, split_col_idx]\n",
    "\n",
    "        if(self.is_numerical(col_name)):\n",
    "            data_left = data[col <= split_val]\n",
    "            data_right = data[col > split_val]\n",
    "        else:\n",
    "            data_left = data[col == split_val]\n",
    "            data_right = data[col != split_val]\n",
    "\n",
    "        return data_left, data_right\n",
    "\n",
    "    \n",
    "    def find_best_split(self, potential_split_dict, data):\n",
    "        split_col = None\n",
    "        split_val = None\n",
    "        overall_mse = None\n",
    "        for col_idx in potential_split_dict:\n",
    "            for split_value in potential_split_dict[col_idx]:\n",
    "                data_left, data_right = self.split_data(col_idx, split_value, data)                \n",
    "                mse = self.find_mean_squared_error(data_left, data_right)\n",
    "                if(overall_mse is None):                    \n",
    "                    overall_mse = mse\n",
    "                    split_col = col_idx\n",
    "                    split_val = split_value\n",
    "                else:\n",
    "                    if mse < overall_mse:\n",
    "                        overall_mse = mse\n",
    "                        split_col = col_idx\n",
    "                        split_val = split_value\n",
    "        return split_col, split_val\n",
    "\n",
    "\n",
    "    def build_decision_tree(self, data, depth, max_depth):\n",
    "        if((depth == max_depth) or self.is_pure(data)):\n",
    "            return data[:,-1].mean()\n",
    "        else:\n",
    "            potential_split_dict = self.find_potential_splits(data)\n",
    "            best_split_col, best_split_val = self.find_best_split(potential_split_dict, data)\n",
    "            # print(\"best_split_col, best_split_val \", best_split_col, best_split_val)\n",
    "            data_left, data_right = self.split_data(best_split_col, best_split_val, data)\n",
    "\n",
    "            left_branch = self.build_decision_tree(data_left, depth + 1, max_depth)\n",
    "            right_branch = self.build_decision_tree(data_right, depth + 1, max_depth)\n",
    "\n",
    "            global col_to_idx\n",
    "            col_name = col_to_idx[best_split_col]\n",
    "            tag=str(col_name)+\" \"+str(best_split_val)\n",
    "            subtree = {}\n",
    "            subtree[tag]=[]\n",
    "\n",
    "            if(left_branch == right_branch):\n",
    "                subtree = left_branch\n",
    "            elif(left_branch != right_branch):\n",
    "                subtree[tag].append(left_branch)\n",
    "                subtree[tag].append(right_branch)\n",
    "            return subtree\n",
    "\n",
    "\n",
    "    def predict_from_tree(self, row, tree):\n",
    "        root = list(tree.keys())[0]\n",
    "        split_col_name, split_value = root.split(\" \")\n",
    "\n",
    "        if self.is_numerical(split_col_name):\n",
    "            p = self.find_for_numerical_data(row, split_col_name, split_value)\n",
    "        else:\n",
    "            p = self.find_for_categorical_data(row, split_col_name, split_value)\n",
    "        ans = tree[root][p]\n",
    "\n",
    "        #base case\n",
    "        if not isinstance(ans, dict):\n",
    "            return ans        \n",
    "        else:\n",
    "            return self.predict_from_tree(row, ans)\n",
    "\n",
    "\n",
    "    def predict_util(self, test_df):\n",
    "        predicted = []\n",
    "        for idx in range(test_df.shape[0]):\n",
    "            # validation_label = test_df.iloc[idx, -1]\n",
    "            # print(\"validation_label: \", validation_label)\n",
    "            predicted_label = self.predict_from_tree(test_df.iloc[idx], self.tree)\n",
    "            # print(\"predicted_label: \", predicted_label)\n",
    "            predicted.append(predicted_label)\n",
    "        return predicted\n",
    "\n",
    "\n",
    "    def predict(self, test_file):\n",
    "        self.test_df = pd.read_csv(test_file)[:]\n",
    "        self.test_df=self.test_df.drop(\"Id\", axis=1) #dropping the id col\n",
    "        self.test_df = self.clean_data(self.test_df)\n",
    "        return self.predict_util(self.test_df)\n",
    "\n",
    "\n",
    "    def train(self, train_file_name):\n",
    "        df=pd.read_csv(train_file_name)[:]\n",
    "        df=df.drop(\"Id\", axis=1) #dropping the id col\n",
    "        df = self.clean_data(df)\n",
    "\n",
    "        global col_to_idx\n",
    "        col_to_idx = {}\n",
    "        self.map_col_to_index(df)\n",
    "\n",
    "        #self.train_df, validation_df = self.train_validation_split(df)\n",
    "        \n",
    "        self.train_df = df\n",
    "        #not slicing the last col (labelcol from train_df, though have kept \n",
    "        #in mind not to use the last col for computation\n",
    "        \n",
    "        #self.label_of_train_data = df.iloc[:,-1] #last column has the actual Sales Prices\n",
    "        \n",
    "        self.tree = self.build_decision_tree(self.train_df.values, depth=0, max_depth=5)\n",
    "        # pprint(decision_tree)\n",
    "\n",
    "dtree_regressor=DecisionTree()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (\"MSE: \", mean_squared_error(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567822567.8869746"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26566.34351110781"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033338868665977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_labels, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
